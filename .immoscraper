from bs4 import BeautifulSoup
import requests
from urllib.parse import urljoin
import pandas as pd

class ScrapedRealEstate():
    def __init__(self, nutzungsart, vermarktungsart, objektart, neubau, plz, ort, strasse, wohnflaeche, grundstuecksflaeche, anzahl_zimmer, anzahl_schlafzimmer, anzahl_badezimmer, urspruenglicher_angebotspreis, angebotspreis, realer_kaufpreis, baujahr, zustand, etagen_zahl, balkon, terrasse, unterkellert, energieausweisbaujahr, auftragvon, auftragbis, auftragsart, verkauft_am):
        self.nutzungsart = nutzungsart
        self.vermarktungsart = vermarktungsart
        self.objektart = objektart
        self.neubau = neubau
        self.plz = plz
        self.ort = ort
        self.strasse = strasse
        self.wohnflaeche = wohnflaeche
        self.grundstuecksflaeche = grundstuecksflaeche
        self.anzahl_zimmer = anzahl_zimmer
        self.anzahl_schlafzimmer = anzahl_schlafzimmer
        self.anzahl_badezimmer = anzahl_badezimmer
        self.urspruenglicher_angebotspreis = urspruenglicher_angebotspreis
        self.angebotspreis = angebotspreis
        self.realer_kaufpreis = realer_kaufpreis
        self.baujahr = baujahr
        self.zustand = zustand
        self.etagen_zahl = etagen_zahl
        self.balkon = balkon
        self.terrasse = terrasse
        self.unterkellert = unterkellert
        self.energieausweisbaujahr = energieausweisbaujahr
        self.auftragvon = auftragvon
        self.auftragbis = auftragbis
        self.auftragsart = auftragsart
        self.verkauft_am = verkauft_am    
        

class ImmoFetcher():
    def fetch(self):
        url = 'https://www.immonet.de/immobiliensuche/sel.do?suchart=2&longitude=9.956450498378357&city=153145&marketingtype=1&pageoffset=702&radius=50&parentcat=2&listsize=27&latitude=49.73796676018255&sortby=16&objecttype=1&page=1'
        inventory = []
        
        while url != '':
            print(url)
            r = requests.get(url)
            soup = BeautifulSoup(r.text, 'html.parser')
            containers = soup.find_all('div', class_='flex-grow-1 display-flex flex-direction-column box-25 overflow-hidden cursor-hand')
            for container in containers:

                objektart = 'haus'

                nutzungsart = 'wohnen'

                vermarktungsart = 'kauf'

                strasse = ''

                urspruenglicher_angebotspreis = '0'

                realer_kaufpreis = ''

                auftragvon = ''

                auftragbis = ''

                auftragsart = ''

                verkauft_am = ''


                moredata = container.find('a', class_='block ellipsis text-225 text-default')
                diverse_page = moredata.attrs['href']
                diverse_page = urljoin(url,diverse_page)
                print(diverse_page)
                

                v = requests.get(diverse_page)
                soup2 = BeautifulSoup(v.text, 'html.parser')

                
                ort = soup2.find('p', class_='text-100 pull-left').text.strip().split()[-4]

                
                plz = soup2.find('p', class_='text-100 pull-left').text.strip().split()[-5]

                
                angebotspreis = soup2.find('div', id = 'priceid_1')
                if angebotspreis != None:
                    angebotspreis = soup2.find('div', id = 'priceid_1').text.strip().split()[0]
                else:
                    angebotspreis = ''


                anzahl_zimmer = soup2.find('div', id = 'equipmentid_1')
                if anzahl_zimmer != None:
                    anzahl_zimmer = soup2.find('div', id = 'equipmentid_1').text.strip().split()[0]
                else:
                    anzahl_zimmer = '0'
               

                wohnflaeche = soup2.find('div', id = 'areaid_1')
                if wohnflaeche != None:
                    wohnflaeche = soup2.find('div', id = 'areaid_1').text.strip().split()[0]
                else:
                    wohnflaeche = '0'
                

                baujahr = soup2.find('div', id = 'yearbuild')
                if baujahr != None:
                    baujahr = soup2.find('div', id = 'yearbuild').text.strip().split()[0]
                else:
                    baujahr = ''
                

                energieausweisbaujahr = soup2.find('div', id = 'yearBuildByPassValue')
                if energieausweisbaujahr != None:
                    energieausweisbaujahr = soup2.find('div', id = 'yearBuildByPassValue').text.strip()
                elif baujahr != None:
                    energieausweisbaujahr = baujahr
                else:
                    energieausweisbaujahr = ''
                

                grundstuecksflaeche = soup2.find('div', id = 'areaid_3')
                if grundstuecksflaeche != None:
                    grundstuecksflaeche = soup2.find('div', id = 'areaid_3').text.strip().split()[0]
                else:
                    grundstuecksflaeche = '0'
                print('grundstücksfläche in m²: ' + grundstuecksflaeche)

                
                zustand = soup2.find('div', id = 'objectstatecategoryValue')
                if zustand != None:
                    zustand = soup2.find('div', id = 'objectstatecategoryValue').text.strip()
                else:
                    zustand = ''
                

                neubau = soup2.find('div', id = 'objectstatecategoryValue')
                if neubau != None:
                    neubau = soup2.find('div', id = 'objectstatecategoryValue').text.strip()
                    if neubau == 'Neubau':
                        neubau = '1'
                    else:
                        neubau = '0'
                else:
                    neubau = '0'
                

                etagen_zahl = soup2.find('li', id = 'featureId_135')
                if etagen_zahl != None:
                    etagen_zahl = soup2.find('li', id = 'featureId_135').text.strip().split()[-1]
                else:
                    etagen_zahl = '0'
                

                balkon = soup2.find('li', id = 'featureId_57')
                if balkon != None:
                    balkon = '1'
                else:
                    balkon = '0'
                

                terrasse = soup2.find('li', id = 'featureId_67')
                if terrasse != None:
                    terrasse = '1'
                else:
                    terrasse = '0'
                

                unterkellert = soup2.find('li', id = 'featureId_69')
                if unterkellert != None:
                    unterkellert = 'JA'
                else:
                    unterkellert = 'NEIN'
                

                anzahl_schlafzimmer = soup2.find('p', id = 'otherDescription')
                if anzahl_schlafzimmer != None:
                    anzahl_schlafzimmer = soup2.find('p', id = 'otherDescription').text.strip().split()
                    if 'Schlafzimmer:' in anzahl_schlafzimmer:
                        index_beginn = anzahl_schlafzimmer.index('Schlafzimmer:')
                        anzahl_schlafzimmer1 = soup2.find('p', id = 'otherDescription').text.strip().split()[index_beginn:]
                        anzahl_schlafzimmer = anzahl_schlafzimmer1[1][0]
                    else:
                        anzahl_schlafzimmer = '0'

                else:
                    anzahl_schlafzimmer = '0'
                
                

                anzahl_badezimmer = soup2.find('p', id = 'otherDescription')
                if anzahl_badezimmer != None:
                    anzahl_badezimmer = soup2.find('p', id = 'otherDescription').text.strip().split()
                    if 'Badezimmer:' in anzahl_badezimmer:
                        index_beginn = anzahl_badezimmer.index('Badezimmer:')
                        anzahl_badezimmer = soup2.find('p', id = 'otherDescription').text.strip().split()[index_beginn:]
                        anzahl_badezimmer = anzahl_badezimmer[1][0]
                    else:
                        anzahl_badezimmer = '0'

                elif soup2.find('li', id = 'featureId_35') != None:
                    anzahl_badezimmer = '1'

                else:
                    anzahl_badezimmer = '0'
                
                
                        
                scraped = ScrapedRealEstate(nutzungsart, vermarktungsart, objektart, neubau, plz, ort, strasse, wohnflaeche, grundstuecksflaeche, anzahl_zimmer, anzahl_schlafzimmer, anzahl_badezimmer, urspruenglicher_angebotspreis, angebotspreis, realer_kaufpreis, baujahr, zustand, etagen_zahl, balkon, terrasse, unterkellert, energieausweisbaujahr, auftragvon, auftragbis, auftragsart, verkauft_am)
                inventory.append(scraped)
                
            next_button = soup.find('a', class_= 'col-sm-3 col-xs-1 pull-right text-right')
            if next_button:
                next_href = next_button.attrs["href"]
                next_href = urljoin(url, next_href)            
                url = next_href
            else:
                url = ''
        
        return inventory




import csv
fetcher = ImmoFetcher()

with open('immonet_kauf.csv', 'w', newline='', encoding='utf-8') as csvfile:
    realestatewriter = csv.writer(csvfile, delimiter=';', quotechar='"', quoting=csv.QUOTE_MINIMAL)
    realestatewriter.writerow(['nutzungsart', 'vermarktungsart', 'objektart', 'neubau', 'plz', 'ort', 'strasse', 'wohnflaeche', 'grundstuecksflaeche', 'anzahl_zimmer', 'anzahl_schlafzimmer', 'anzahl_badezimmer', 'Ursprünglicher Angebotspreis', 'Angebotspreis', 'Realer Kaufpreis', 'baujahr', 'zustand', 'etagen_zahl', 'balkon', 'terrasse', 'unterkellert', 'energieausweisbaujahr', 'auftragvon', 'auftragbis', 'auftragsart', 'verkauft_am'])
    
    for x in fetcher.fetch():
        realestatewriter.writerow([x.nutzungsart, x.vermarktungsart, x.objektart, x.neubau, x.plz, x.ort, x.strasse, x.wohnflaeche, x.grundstuecksflaeche, x.anzahl_zimmer, x.anzahl_schlafzimmer, x.anzahl_badezimmer, x.urspruenglicher_angebotspreis, x.angebotspreis, x.realer_kaufpreis, x.baujahr, x.zustand, x.etagen_zahl, x.balkon, x.terrasse, x.unterkellert, x.energieausweisbaujahr, x.auftragvon, x.auftragbis, x.auftragsart, x.verkauft_am])



df = pd.read_csv('immonet_kauf.csv', ';')
df
